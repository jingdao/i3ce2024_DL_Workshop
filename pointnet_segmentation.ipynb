{"cells":[{"cell_type":"markdown","source":["# i3ce 2024: Workshop on Deep Learning Tools for Understanding and Modeling the Built Environment\n","\n","In this workshop, we will implement a deep learning pipeline to perform semantic segmentation, i.e. point-wise classification, for 3D point clouds of buildings.\n","\n","The dataset for this workshop is taken from Stanford 3D Indoor Scene Dataset [S3DIS](http://buildingparser.stanford.edu/dataset.html).\n","\n","The neural network architecture will be based on [PointNet](https://arxiv.org/abs/1612.00593), *Qi et al. (2017) PointNet: Deep Learning on Point Sets for 3D Classification and Segmentation*. The original source code for PointNet can be found [here](https://github.com/charlesq34/pointnet/blob/master/models/pointnet_cls.py).\n","\n","A basic PyTorch tutorial can be found here:\n","[link](https://pytorch.org/tutorials/beginner/basics/quickstart_tutorial.html).\n","Doing the tutorial is optional but it should help explain many concepts that we will cover in this workshop."],"metadata":{"id":"MqR0pagR49WH"}},{"cell_type":"markdown","source":["# Part 1: Setup"],"metadata":{"id":"xhUH2DTb6C9B"}},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":31240,"status":"ok","timestamp":1721860798626,"user":{"displayName":"Jing Dao Chen","userId":"06340163517236512087"},"user_tz":300},"id":"JdYLKLOzA6fb","outputId":"2ec2a4b0-bef2-4a2f-db05-629d42dcb833"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting open3d\n","  Downloading open3d-0.18.0-cp310-cp310-manylinux_2_27_x86_64.whl.metadata (4.2 kB)\n","Requirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.10/dist-packages (from open3d) (1.25.2)\n","Collecting dash>=2.6.0 (from open3d)\n","  Downloading dash-2.17.1-py3-none-any.whl.metadata (10 kB)\n","Requirement already satisfied: werkzeug>=2.2.3 in /usr/local/lib/python3.10/dist-packages (from open3d) (3.0.3)\n","Requirement already satisfied: nbformat>=5.7.0 in /usr/local/lib/python3.10/dist-packages (from open3d) (5.10.4)\n","Collecting configargparse (from open3d)\n","  Downloading ConfigArgParse-1.7-py3-none-any.whl.metadata (23 kB)\n","Collecting ipywidgets>=8.0.4 (from open3d)\n","  Downloading ipywidgets-8.1.3-py3-none-any.whl.metadata (2.4 kB)\n","Collecting addict (from open3d)\n","  Downloading addict-2.4.0-py3-none-any.whl.metadata (1.0 kB)\n","Requirement already satisfied: pillow>=9.3.0 in /usr/local/lib/python3.10/dist-packages (from open3d) (9.4.0)\n","Requirement already satisfied: matplotlib>=3 in /usr/local/lib/python3.10/dist-packages (from open3d) (3.7.1)\n","Requirement already satisfied: pandas>=1.0 in /usr/local/lib/python3.10/dist-packages (from open3d) (2.0.3)\n","Requirement already satisfied: pyyaml>=5.4.1 in /usr/local/lib/python3.10/dist-packages (from open3d) (6.0.1)\n","Requirement already satisfied: scikit-learn>=0.21 in /usr/local/lib/python3.10/dist-packages (from open3d) (1.2.2)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from open3d) (4.66.4)\n","Collecting pyquaternion (from open3d)\n","  Downloading pyquaternion-0.9.9-py3-none-any.whl.metadata (1.4 kB)\n","Requirement already satisfied: Flask<3.1,>=1.0.4 in /usr/local/lib/python3.10/dist-packages (from dash>=2.6.0->open3d) (2.2.5)\n","Requirement already satisfied: plotly>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from dash>=2.6.0->open3d) (5.15.0)\n","Collecting dash-html-components==2.0.0 (from dash>=2.6.0->open3d)\n","  Downloading dash_html_components-2.0.0-py3-none-any.whl.metadata (3.8 kB)\n","Collecting dash-core-components==2.0.0 (from dash>=2.6.0->open3d)\n","  Downloading dash_core_components-2.0.0-py3-none-any.whl.metadata (2.9 kB)\n","Collecting dash-table==5.0.0 (from dash>=2.6.0->open3d)\n","  Downloading dash_table-5.0.0-py3-none-any.whl.metadata (2.4 kB)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.10/dist-packages (from dash>=2.6.0->open3d) (8.0.0)\n","Requirement already satisfied: typing-extensions>=4.1.1 in /usr/local/lib/python3.10/dist-packages (from dash>=2.6.0->open3d) (4.12.2)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from dash>=2.6.0->open3d) (2.31.0)\n","Collecting retrying (from dash>=2.6.0->open3d)\n","  Downloading retrying-1.3.4-py3-none-any.whl.metadata (6.9 kB)\n","Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.10/dist-packages (from dash>=2.6.0->open3d) (1.6.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from dash>=2.6.0->open3d) (71.0.4)\n","Collecting comm>=0.1.3 (from ipywidgets>=8.0.4->open3d)\n","  Downloading comm-0.2.2-py3-none-any.whl.metadata (3.7 kB)\n","Requirement already satisfied: ipython>=6.1.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets>=8.0.4->open3d) (7.34.0)\n","Requirement already satisfied: traitlets>=4.3.1 in /usr/local/lib/python3.10/dist-packages (from ipywidgets>=8.0.4->open3d) (5.7.1)\n","Collecting widgetsnbextension~=4.0.11 (from ipywidgets>=8.0.4->open3d)\n","  Downloading widgetsnbextension-4.0.11-py3-none-any.whl.metadata (1.6 kB)\n","Requirement already satisfied: jupyterlab-widgets~=3.0.11 in /usr/local/lib/python3.10/dist-packages (from ipywidgets>=8.0.4->open3d) (3.0.11)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3->open3d) (1.2.1)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3->open3d) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3->open3d) (4.53.1)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3->open3d) (1.4.5)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3->open3d) (24.1)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3->open3d) (3.1.2)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3->open3d) (2.8.2)\n","Requirement already satisfied: fastjsonschema>=2.15 in /usr/local/lib/python3.10/dist-packages (from nbformat>=5.7.0->open3d) (2.20.0)\n","Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.10/dist-packages (from nbformat>=5.7.0->open3d) (4.19.2)\n","Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in /usr/local/lib/python3.10/dist-packages (from nbformat>=5.7.0->open3d) (5.7.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0->open3d) (2023.4)\n","Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0->open3d) (2024.1)\n","Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21->open3d) (1.11.4)\n","Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21->open3d) (1.4.2)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21->open3d) (3.5.0)\n","Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=2.2.3->open3d) (2.1.5)\n","Requirement already satisfied: Jinja2>=3.0 in /usr/local/lib/python3.10/dist-packages (from Flask<3.1,>=1.0.4->dash>=2.6.0->open3d) (3.1.4)\n","Requirement already satisfied: itsdangerous>=2.0 in /usr/local/lib/python3.10/dist-packages (from Flask<3.1,>=1.0.4->dash>=2.6.0->open3d) (2.2.0)\n","Requirement already satisfied: click>=8.0 in /usr/local/lib/python3.10/dist-packages (from Flask<3.1,>=1.0.4->dash>=2.6.0->open3d) (8.1.7)\n","Collecting jedi>=0.16 (from ipython>=6.1.0->ipywidgets>=8.0.4->open3d)\n","  Downloading jedi-0.19.1-py2.py3-none-any.whl.metadata (22 kB)\n","Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (4.4.2)\n","Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (0.7.5)\n","Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (3.0.47)\n","Requirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (2.16.1)\n","Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (0.2.0)\n","Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (0.1.7)\n","Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (4.9.0)\n","Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat>=5.7.0->open3d) (23.2.0)\n","Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat>=5.7.0->open3d) (2023.12.1)\n","Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat>=5.7.0->open3d) (0.35.1)\n","Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat>=5.7.0->open3d) (0.19.0)\n","Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.10/dist-packages (from jupyter-core!=5.0.*,>=4.12->nbformat>=5.7.0->open3d) (4.2.2)\n","Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from plotly>=5.0.0->dash>=2.6.0->open3d) (8.5.0)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3->open3d) (1.16.0)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata->dash>=2.6.0->open3d) (3.19.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->dash>=2.6.0->open3d) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->dash>=2.6.0->open3d) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->dash>=2.6.0->open3d) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->dash>=2.6.0->open3d) (2024.7.4)\n","Requirement already satisfied: parso<0.9.0,>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (0.8.4)\n","Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (0.7.0)\n","Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (0.2.13)\n","Downloading open3d-0.18.0-cp310-cp310-manylinux_2_27_x86_64.whl (399.7 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m399.7/399.7 MB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading dash-2.17.1-py3-none-any.whl (7.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.5/7.5 MB\u001b[0m \u001b[31m61.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading dash_core_components-2.0.0-py3-none-any.whl (3.8 kB)\n","Downloading dash_html_components-2.0.0-py3-none-any.whl (4.1 kB)\n","Downloading dash_table-5.0.0-py3-none-any.whl (3.9 kB)\n","Downloading ipywidgets-8.1.3-py3-none-any.whl (139 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.4/139.4 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading addict-2.4.0-py3-none-any.whl (3.8 kB)\n","Downloading ConfigArgParse-1.7-py3-none-any.whl (25 kB)\n","Downloading pyquaternion-0.9.9-py3-none-any.whl (14 kB)\n","Downloading comm-0.2.2-py3-none-any.whl (7.2 kB)\n","Downloading widgetsnbextension-4.0.11-py3-none-any.whl (2.3 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m60.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading retrying-1.3.4-py3-none-any.whl (11 kB)\n","Downloading jedi-0.19.1-py2.py3-none-any.whl (1.6 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m50.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: dash-table, dash-html-components, dash-core-components, addict, widgetsnbextension, retrying, pyquaternion, jedi, configargparse, comm, ipywidgets, dash, open3d\n","  Attempting uninstall: widgetsnbextension\n","    Found existing installation: widgetsnbextension 3.6.7\n","    Uninstalling widgetsnbextension-3.6.7:\n","      Successfully uninstalled widgetsnbextension-3.6.7\n","  Attempting uninstall: ipywidgets\n","    Found existing installation: ipywidgets 7.7.1\n","    Uninstalling ipywidgets-7.7.1:\n","      Successfully uninstalled ipywidgets-7.7.1\n","Successfully installed addict-2.4.0 comm-0.2.2 configargparse-1.7 dash-2.17.1 dash-core-components-2.0.0 dash-html-components-2.0.0 dash-table-5.0.0 ipywidgets-8.1.3 jedi-0.19.1 open3d-0.18.0 pyquaternion-0.9.9 retrying-1.3.4 widgetsnbextension-4.0.11\n"]}],"source":["# Install the Open3D library for point cloud processing and visualization\n","# This step is necessary because Open3D is not included by default on Google Colab\n","!pip install open3d"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":23346,"status":"ok","timestamp":1721860767388,"user":{"displayName":"Jing Dao Chen","userId":"06340163517236512087"},"user_tz":300},"id":"0UUkmzF0BhsM","outputId":"18e6b734-6c67-4a66-9fde-fb93caa4748a"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","/content/drive/MyDrive/i3ce 2024 DL Workshop/code\n"]}],"source":["# Mount a Google Drive folder so that the data files can be accessed\n","from google.colab import drive\n","from google.colab import files\n","import sys\n","drive.mount('/content/drive', force_remount=True)\n","%cd drive/MyDrive/i3ce 2024 DL Workshop/code/\n","sys.path.insert(0,'/content/drive/MyDrive/i3ce 2024 DL Workshop/code/')"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":259,"status":"ok","timestamp":1721860817984,"user":{"displayName":"Jing Dao Chen","userId":"06340163517236512087"},"user_tz":300},"id":"od7Avg_cBGKv"},"outputs":[],"source":["# Import the necessary libraries and utility functions\n","import numpy as np\n","import torch\n","import torch.nn.functional as F\n","import open3d as o3d\n","\n","# This file contains the model definition for PointNet\n","from pointnet import PointNet\n","\n","# This file contains the data loader code for the S3DIS dataset\n","from dataloader_s3dis import SemSegDataset, class_names, class_colors\n","\n","# This file contains the code for drawing 3D point clouds in a Python notebook\n","from utils import draw_geometries"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":273,"status":"ok","timestamp":1721860820866,"user":{"displayName":"Jing Dao Chen","userId":"06340163517236512087"},"user_tz":300},"id":"2S7BRNj7BPQP"},"outputs":[],"source":[" # define training parameters for deep learning\n","learning_rate = 2e-4\n","batch_size = 10\n","max_epochs = 1000\n","num_resampled_points = 1024\n","num_class = len(class_names)"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2215,"status":"ok","timestamp":1721860824669,"user":{"displayName":"Jing Dao Chen","userId":"06340163517236512087"},"user_tz":300},"id":"YfXImSs6BX1N","outputId":"e7ae42c7-3978-46b4-bd29-1c70f9fbd0eb"},"outputs":[{"output_type":"stream","name":"stdout","text":["Using device: cuda\n","PointNet model:\n","PointNet(\n","  (conv1): Conv1d(9, 64, kernel_size=(1,), stride=(1,))\n","  (conv2): Conv1d(64, 128, kernel_size=(1,), stride=(1,))\n","  (conv3): Conv1d(128, 1024, kernel_size=(1,), stride=(1,))\n","  (conv4): Conv1d(1088, 256, kernel_size=(1,), stride=(1,))\n","  (conv5): Conv1d(256, 13, kernel_size=(1,), stride=(1,))\n","  (bn1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (bn3): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (bn4): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",")\n"]}],"source":["# Allow the model to be trained on GPU (if the CUDA driver is available)\n","# Google Colab allows using a T4 GPUs for free accounts whereas premium GPUs require a subscription\n","device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","print('Using device:', device)\n","\n","# Create a PointNet model\n","# PointNet consists of 5 convolution and batch norm layers and 1 max pooling layer\n","model = PointNet(num_class = num_class).to(device)\n","print('PointNet model:')\n","print(model)\n","\n","# Create the Adam optimizer, an extension to the stochastic gradient descent algorithm for updating model weights\n","optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"]},{"cell_type":"markdown","source":["# Part 2: Data Loading and Visualization"],"metadata":{"id":"NYcmQvkR6JDH"}},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4042,"status":"ok","timestamp":1721860869895,"user":{"displayName":"Jing Dao Chen","userId":"06340163517236512087"},"user_tz":300},"id":"svmNKmueBqhY","outputId":"5f018346-9467-44a4-d439-c55c55150073"},"outputs":[{"output_type":"stream","name":"stdout","text":["Created dataset from area=1 with 44 rooms\n","Created dataset from area=2 with 40 rooms\n"]}],"source":["# create data loaders for the S3DIS dataset\n","train_dataset = SemSegDataset(root='data', area=1, N=num_resampled_points)\n","train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=1)\n","validation_dataset = SemSegDataset(root='data', area=2, N=num_resampled_points)\n","validation_dataloader = torch.utils.data.DataLoader(validation_dataset, batch_size=batch_size, shuffle=True, num_workers=1)\n","num_train_batches = int(np.ceil(len(train_dataset) / batch_size))\n","num_validation_batches = int(np.ceil(len(validation_dataset) / batch_size))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/","height":542,"output_embedded_package_id":"1aP3NKzZUtDEYUpWhHOeKjj-lYyBYVRZK"},"executionInfo":{"elapsed":22856,"status":"ok","timestamp":1719420210182,"user":{"displayName":"Jing Dao Chen","userId":"06340163517236512087"},"user_tz":300},"id":"JPWgYArjCh6X","outputId":"579d9966-5f7d-442e-bd7d-c78b3be4f9a7"},"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}],"source":["# visualize labels in training dataset by plotting colored point clouds\n","visualized_objects = []\n","\n","# only visualize a small number of rooms to prevent memory overflow\n","num_rooms_to_visualize = 10\n","#num_rooms_to_visualize = len(train_dataset)\n","\n","for i in range(num_rooms_to_visualize):\n","  pcd_object = o3d.geometry.PointCloud()\n","  pcd_object.points = o3d.utility.Vector3dVector(train_dataset.points[i][:, :3])\n","  # assign colors based on the ground truth class label for each point\n","  pcd_object.colors = o3d.utility.Vector3dVector(np.array(class_colors)[train_dataset.labels[i]])\n","  visualized_objects.append(pcd_object)\n","\n","\n","# Visualize the point cloud using a 3D web viewer\n","draw_geometries(visualized_objects, show_axes=True)"]},{"cell_type":"markdown","source":["# Part 3: Training"],"metadata":{"id":"ug2UuUBp6NJ8"}},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"faeBADr6BwaI","outputId":"2f50120d-1b64-4f4a-d41e-bec0d053468a","executionInfo":{"status":"ok","timestamp":1721861475553,"user_tz":300,"elapsed":184053,"user":{"displayName":"Jing Dao Chen","userId":"06340163517236512087"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["[Epoch 9] train loss: 2.206 accuracy: 0.294\n","[Epoch 19] train loss: 2.190 accuracy: 0.295\n","[Epoch 29] train loss: 2.273 accuracy: 0.213\n","[Epoch 39] train loss: 2.151 accuracy: 0.279\n","[Epoch 49] train loss: 2.204 accuracy: 0.297\n","[Epoch 59] train loss: 2.062 accuracy: 0.321\n","[Epoch 69] train loss: 2.044 accuracy: 0.289\n","[Epoch 79] train loss: 1.857 accuracy: 0.369\n","[Epoch 89] train loss: 1.857 accuracy: 0.402\n","[Epoch 99] train loss: 1.757 accuracy: 0.461\n","[Epoch 99] validation  loss: 3.346 accuracy: 0.360\n","   clutter: recall 0.000 precision 0.000\n","     board: recall 0.000 precision 0.000\n","  bookcase: recall 0.000 precision 0.000\n","      beam: recall 0.000 precision 0.000\n","     chair: recall 0.000 precision 0.000\n","    column: recall 0.000 precision 0.000\n","      door: recall 0.000 precision 0.000\n","      sofa: recall 0.000 precision 0.000\n","     table: recall 0.000 precision 0.000\n","    window: recall 0.000 precision 0.000\n","   ceiling: recall 0.646 precision 0.057\n","     floor: recall 0.536 precision 0.081\n","      wall: recall 0.352 precision 0.991\n","[Epoch 109] train loss: 1.819 accuracy: 0.385\n","[Epoch 119] train loss: 1.807 accuracy: 0.407\n","[Epoch 129] train loss: 1.737 accuracy: 0.441\n","[Epoch 139] train loss: 1.708 accuracy: 0.448\n","[Epoch 149] train loss: 1.722 accuracy: 0.458\n","[Epoch 159] train loss: 1.656 accuracy: 0.467\n","[Epoch 169] train loss: 1.625 accuracy: 0.436\n","[Epoch 179] train loss: 1.644 accuracy: 0.434\n","[Epoch 189] train loss: 1.646 accuracy: 0.466\n","[Epoch 199] train loss: 1.636 accuracy: 0.484\n","[Epoch 199] validation  loss: 2.223 accuracy: 0.375\n","   clutter: recall 0.180 precision 0.026\n","     board: recall 0.000 precision 0.000\n","  bookcase: recall 0.000 precision 0.000\n","      beam: recall 0.000 precision 0.000\n","     chair: recall 0.000 precision 0.000\n","    column: recall 0.000 precision 0.000\n","      door: recall 0.091 precision 0.035\n","      sofa: recall 0.000 precision 0.000\n","     table: recall 0.000 precision 0.000\n","    window: recall 0.000 precision 0.000\n","   ceiling: recall 0.718 precision 0.056\n","     floor: recall 0.608 precision 0.274\n","      wall: recall 0.368 precision 0.937\n","[Epoch 209] train loss: 1.571 accuracy: 0.496\n","[Epoch 219] train loss: 1.602 accuracy: 0.490\n","[Epoch 229] train loss: 1.530 accuracy: 0.492\n","[Epoch 239] train loss: 1.512 accuracy: 0.499\n","[Epoch 249] train loss: 1.486 accuracy: 0.494\n","[Epoch 259] train loss: 1.490 accuracy: 0.512\n","[Epoch 269] train loss: 1.469 accuracy: 0.520\n","[Epoch 279] train loss: 1.437 accuracy: 0.524\n","[Epoch 289] train loss: 1.441 accuracy: 0.516\n","[Epoch 299] train loss: 1.450 accuracy: 0.520\n","[Epoch 299] validation  loss: 1.699 accuracy: 0.500\n","   clutter: recall 0.144 precision 0.027\n","     board: recall 0.000 precision 0.000\n","  bookcase: recall 0.000 precision 0.000\n","      beam: recall 0.000 precision 0.000\n","     chair: recall 0.097 precision 0.014\n","    column: recall 0.000 precision 0.000\n","      door: recall 0.000 precision 0.000\n","      sofa: recall 0.000 precision 0.000\n","     table: recall 0.000 precision 0.000\n","    window: recall 0.000 precision 0.000\n","   ceiling: recall 0.596 precision 0.823\n","     floor: recall 0.524 precision 0.818\n","      wall: recall 0.478 precision 0.738\n","[Epoch 309] train loss: 1.397 accuracy: 0.526\n","[Epoch 319] train loss: 1.412 accuracy: 0.533\n","[Epoch 329] train loss: 1.399 accuracy: 0.534\n","[Epoch 339] train loss: 1.393 accuracy: 0.531\n","[Epoch 349] train loss: 1.387 accuracy: 0.527\n","[Epoch 359] train loss: 1.361 accuracy: 0.541\n","[Epoch 369] train loss: 1.405 accuracy: 0.527\n","[Epoch 379] train loss: 1.351 accuracy: 0.549\n","[Epoch 389] train loss: 1.316 accuracy: 0.557\n","[Epoch 399] train loss: 1.370 accuracy: 0.553\n","[Epoch 399] validation  loss: 1.610 accuracy: 0.493\n","   clutter: recall 0.261 precision 0.106\n","     board: recall 0.000 precision 0.000\n","  bookcase: recall 0.195 precision 0.203\n","      beam: recall 0.026 precision 0.007\n","     chair: recall 0.000 precision 0.000\n","    column: recall 0.000 precision 0.000\n","      door: recall 0.109 precision 0.005\n","      sofa: recall 0.000 precision 0.000\n","     table: recall 0.000 precision 0.000\n","    window: recall 0.000 precision 0.000\n","   ceiling: recall 0.842 precision 0.423\n","     floor: recall 0.632 precision 0.820\n","      wall: recall 0.461 precision 0.834\n","[Epoch 409] train loss: 1.307 accuracy: 0.560\n","[Epoch 419] train loss: 1.329 accuracy: 0.552\n","[Epoch 429] train loss: 1.328 accuracy: 0.553\n","[Epoch 439] train loss: 1.299 accuracy: 0.567\n","[Epoch 449] train loss: 1.291 accuracy: 0.571\n","[Epoch 459] train loss: 1.267 accuracy: 0.578\n","[Epoch 469] train loss: 1.315 accuracy: 0.561\n","[Epoch 479] train loss: 1.281 accuracy: 0.560\n","[Epoch 489] train loss: 1.251 accuracy: 0.573\n","[Epoch 499] train loss: 1.305 accuracy: 0.566\n","[Epoch 499] validation  loss: 1.742 accuracy: 0.537\n","   clutter: recall 0.265 precision 0.153\n","     board: recall 0.000 precision 0.000\n","  bookcase: recall 0.288 precision 0.071\n","      beam: recall 0.000 precision 0.000\n","     chair: recall 0.199 precision 0.051\n","    column: recall 0.000 precision 0.000\n","      door: recall 0.281 precision 0.136\n","      sofa: recall 0.000 precision 0.000\n","     table: recall 0.051 precision 0.003\n","    window: recall 0.000 precision 0.000\n","   ceiling: recall 0.708 precision 0.800\n","     floor: recall 0.592 precision 0.894\n","      wall: recall 0.543 precision 0.735\n","[Epoch 509] train loss: 1.240 accuracy: 0.580\n","[Epoch 519] train loss: 1.251 accuracy: 0.578\n","[Epoch 529] train loss: 1.249 accuracy: 0.565\n","[Epoch 539] train loss: 1.204 accuracy: 0.592\n","[Epoch 549] train loss: 1.277 accuracy: 0.556\n","[Epoch 559] train loss: 1.247 accuracy: 0.574\n","[Epoch 569] train loss: 1.230 accuracy: 0.574\n","[Epoch 579] train loss: 1.248 accuracy: 0.560\n","[Epoch 589] train loss: 1.225 accuracy: 0.575\n","[Epoch 599] train loss: 1.233 accuracy: 0.578\n","[Epoch 599] validation  loss: 1.817 accuracy: 0.465\n","   clutter: recall 0.297 precision 0.085\n","     board: recall 0.000 precision 0.000\n","  bookcase: recall 0.323 precision 0.079\n","      beam: recall 0.014 precision 0.004\n","     chair: recall 0.000 precision 0.000\n","    column: recall 0.000 precision 0.000\n","      door: recall 0.212 precision 0.160\n","      sofa: recall 0.000 precision 0.000\n","     table: recall 0.000 precision 0.000\n","    window: recall 0.000 precision 0.000\n","   ceiling: recall 0.831 precision 0.179\n","     floor: recall 0.677 precision 0.787\n","      wall: recall 0.434 precision 0.862\n","[Epoch 609] train loss: 1.241 accuracy: 0.590\n","[Epoch 619] train loss: 1.256 accuracy: 0.584\n","[Epoch 629] train loss: 1.247 accuracy: 0.579\n","[Epoch 639] train loss: 1.269 accuracy: 0.573\n","[Epoch 649] train loss: 1.182 accuracy: 0.596\n","[Epoch 659] train loss: 1.227 accuracy: 0.589\n","[Epoch 669] train loss: 1.249 accuracy: 0.581\n","[Epoch 679] train loss: 1.236 accuracy: 0.585\n","[Epoch 689] train loss: 1.186 accuracy: 0.586\n","[Epoch 699] train loss: 1.208 accuracy: 0.575\n","[Epoch 699] validation  loss: 2.269 accuracy: 0.335\n","   clutter: recall 0.203 precision 0.410\n","     board: recall 0.000 precision 0.000\n","  bookcase: recall 0.286 precision 0.086\n","      beam: recall 0.015 precision 0.015\n","     chair: recall 0.126 precision 0.034\n","    column: recall 0.000 precision 0.000\n","      door: recall 0.168 precision 0.237\n","      sofa: recall 0.000 precision 0.000\n","     table: recall 0.000 precision 0.000\n","    window: recall 0.000 precision 0.000\n","   ceiling: recall 0.824 precision 0.320\n","     floor: recall 0.819 precision 0.028\n","      wall: recall 0.413 precision 0.566\n","[Epoch 709] train loss: 1.235 accuracy: 0.562\n","[Epoch 719] train loss: 1.222 accuracy: 0.579\n","[Epoch 729] train loss: 1.136 accuracy: 0.616\n","[Epoch 739] train loss: 1.207 accuracy: 0.601\n","[Epoch 749] train loss: 1.252 accuracy: 0.583\n","[Epoch 759] train loss: 1.243 accuracy: 0.576\n","[Epoch 769] train loss: 1.248 accuracy: 0.582\n","[Epoch 779] train loss: 1.190 accuracy: 0.586\n","[Epoch 789] train loss: 1.221 accuracy: 0.581\n","[Epoch 799] train loss: 1.195 accuracy: 0.582\n","[Epoch 799] validation  loss: 2.222 accuracy: 0.440\n","   clutter: recall 0.214 precision 0.115\n","     board: recall 0.000 precision 0.000\n","  bookcase: recall 0.179 precision 0.056\n","      beam: recall 0.002 precision 0.002\n","     chair: recall 0.000 precision 0.000\n","    column: recall 0.008 precision 0.004\n","      door: recall 0.203 precision 0.210\n","      sofa: recall 0.000 precision 0.000\n","     table: recall 0.036 precision 0.002\n","    window: recall 0.000 precision 0.000\n","   ceiling: recall 0.755 precision 0.756\n","     floor: recall 0.813 precision 0.082\n","      wall: recall 0.438 precision 0.811\n","[Epoch 809] train loss: 1.204 accuracy: 0.587\n","[Epoch 819] train loss: 1.205 accuracy: 0.581\n","[Epoch 829] train loss: 1.183 accuracy: 0.601\n","[Epoch 839] train loss: 1.164 accuracy: 0.604\n","[Epoch 849] train loss: 1.182 accuracy: 0.597\n","[Epoch 859] train loss: 1.190 accuracy: 0.592\n","[Epoch 869] train loss: 1.225 accuracy: 0.586\n","[Epoch 879] train loss: 1.184 accuracy: 0.594\n","[Epoch 889] train loss: 1.118 accuracy: 0.606\n","[Epoch 899] train loss: 1.153 accuracy: 0.585\n","[Epoch 899] validation  loss: 1.983 accuracy: 0.427\n","   clutter: recall 0.210 precision 0.432\n","     board: recall 0.000 precision 0.000\n","  bookcase: recall 0.142 precision 0.009\n","      beam: recall 0.000 precision 0.000\n","     chair: recall 0.286 precision 0.002\n","    column: recall 0.000 precision 0.000\n","      door: recall 0.221 precision 0.171\n","      sofa: recall 0.000 precision 0.000\n","     table: recall 0.000 precision 0.000\n","    window: recall 0.034 precision 0.092\n","   ceiling: recall 0.729 precision 0.611\n","     floor: recall 0.776 precision 0.363\n","      wall: recall 0.493 precision 0.587\n","[Epoch 909] train loss: 1.170 accuracy: 0.597\n","[Epoch 919] train loss: 1.155 accuracy: 0.600\n","[Epoch 929] train loss: 1.193 accuracy: 0.590\n","[Epoch 939] train loss: 1.159 accuracy: 0.602\n","[Epoch 949] train loss: 1.135 accuracy: 0.605\n","[Epoch 959] train loss: 1.163 accuracy: 0.603\n","[Epoch 969] train loss: 1.180 accuracy: 0.591\n","[Epoch 979] train loss: 1.187 accuracy: 0.586\n","[Epoch 989] train loss: 1.152 accuracy: 0.607\n","[Epoch 999] train loss: 1.123 accuracy: 0.603\n","[Epoch 999] validation  loss: 1.804 accuracy: 0.490\n","   clutter: recall 0.270 precision 0.268\n","     board: recall 0.000 precision 0.000\n","  bookcase: recall 0.165 precision 0.037\n","      beam: recall 0.000 precision 0.000\n","     chair: recall 0.249 precision 0.076\n","    column: recall 0.000 precision 0.000\n","      door: recall 0.273 precision 0.122\n","      sofa: recall 0.000 precision 0.000\n","     table: recall 0.200 precision 0.375\n","    window: recall 0.010 precision 0.030\n","   ceiling: recall 0.706 precision 0.734\n","     floor: recall 0.790 precision 0.516\n","      wall: recall 0.507 precision 0.703\n"]}],"source":["# Run the training and evaluation loop for 1000 epochs\n","# Observe the trend in how the training / validation loss and accuracy values changes over time\n","# After every 100 epochs, we will calculate the recall and precision metrics as well\n","\n","for epoch in range(max_epochs):\n","    train_loss, train_correct, train_accuracy = 0, 0, 0\n","    for i, data in enumerate(train_dataloader):\n","        points, target = data\n","\n","        #put the model in training mode\n","        model = model.train()\n","\n","        #move this batch of data to the GPU if device is cuda\n","        points, target = points.to(device), target.to(device)\n","\n","        # TODO: run a forward pass through the neural network and predict the outputs\n","        pred = model(points)\n","\n","        # TODO: compare the prediction vs the target labels and determine the negative log-likelihood loss\n","        pred_1d = pred.view(-1, num_class)\n","        target_1d = target.view(-1, 1)[:, 0]\n","        loss = F.nll_loss(pred_1d, target_1d)\n","\n","        # TODO: perform backpropagation to update the weights of the network based on the computed loss function\n","        loss.backward()\n","        optimizer.step()\n","\n","        # keep track of the accuracy of our predictions\n","        pred_choice = pred_1d.data.max(1)[1]\n","        train_loss += loss.item()\n","        train_correct += pred_choice.eq(target_1d).sum().item()\n","\n","    train_loss /= num_train_batches\n","    train_accuracy = train_correct / len(train_dataset) / num_resampled_points\n","    if epoch % 10 == 9:\n","      print('[Epoch %d] train loss: %.3f accuracy: %.3f' % (epoch, train_loss, train_accuracy))\n","\n","    if epoch % 100 == 99: # run validation every 100 epochs\n","        validation_loss, validation_correct, validation_accuracy = 0, 0, 0\n","        tp_per_class = [0] * num_class\n","        fp_per_class = [0] * num_class\n","        fn_per_class = [0] * num_class\n","        for j, data in enumerate(validation_dataloader):\n","            points, target = data\n","            points, target = points.to(device), target.to(device)\n","            # put the model in evaluation mode\n","            model = model.eval()\n","            with torch.no_grad():\n","                pred = model(points)\n","                pred_1d = pred.view(-1, num_class)\n","                target_1d = target.view(-1, 1)[:, 0]\n","                loss = F.nll_loss(pred_1d, target_1d)\n","                pred_choice = pred_1d.data.max(1)[1]\n","                validation_loss += loss.item()\n","                validation_correct += pred_choice.eq(target_1d).sum().item()\n","                for i in range(num_class):\n","                    tp_per_class[i] += ((pred_choice==i) & (target_1d==i)).sum().item()\n","                    fp_per_class[i] += ((pred_choice==i) & (target_1d!=i)).sum().item()\n","                    fn_per_class[i] += ((pred_choice!=i) & (target_1d==i)).sum().item()\n","        validation_loss /= num_validation_batches\n","        validation_accuracy = validation_correct / len(validation_dataset) / num_resampled_points\n","        print('[Epoch %d] validation  loss: %.3f accuracy: %.3f' % (epoch, validation_loss, validation_accuracy))\n","        for i in range(num_class):\n","            precision = 1.0 * tp_per_class[i] / (tp_per_class[i] + fp_per_class[i] + 1e-6)\n","            recall = 1.0 * tp_per_class[i] / (tp_per_class[i] + fn_per_class[i] + 1e-6)\n","            print('%10s: recall %.3f precision %.3f' % (class_names[i], precision, recall))\n"]},{"cell_type":"code","execution_count":11,"metadata":{"id":"48aqR47ckAia","executionInfo":{"status":"ok","timestamp":1721861588016,"user_tz":300,"elapsed":222,"user":{"displayName":"Jing Dao Chen","userId":"06340163517236512087"}}},"outputs":[],"source":["# Save the trained model weights in Google Drive so that it can be used later\n","torch.save(model.state_dict(), 'pointnet.pth')"]},{"cell_type":"markdown","source":["# Part 4: Testing"],"metadata":{"id":"vdtNBatZ6qMC"}},{"cell_type":"code","source":["# Create data loader for the test set\n","# Note that the test set is distinct from the training set and the validation set\n","test_dataset = SemSegDataset(root='data', area=3, N=num_resampled_points)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qz1bSYbB6qpu","executionInfo":{"status":"ok","timestamp":1721861590982,"user_tz":300,"elapsed":1558,"user":{"displayName":"Jing Dao Chen","userId":"06340163517236512087"}},"outputId":"f4f5d77e-e580-4860-89cf-bf0f873b1188"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["Created dataset from area=3 with 23 rooms\n"]}]},{"cell_type":"code","source":["# Load the previously saved PointNet model\n","\n","import os\n","model_path = 'pointnet.pth'\n","if os.path.exists(model_path):\n","    print('Loading PointNet model from', model_path)\n","    model.load_state_dict(torch.load(model_path))\n","else:\n","    print('Failed to load model from', model_path)\n","    sys.exit(1)\n","model.eval()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9nxYjfqj6sfX","executionInfo":{"status":"ok","timestamp":1721861596441,"user_tz":300,"elapsed":221,"user":{"displayName":"Jing Dao Chen","userId":"06340163517236512087"}},"outputId":"9b270064-2b2c-446e-dfda-991b68eef6bd"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["Loading PointNet model from pointnet.pth\n"]},{"output_type":"execute_result","data":{"text/plain":["PointNet(\n","  (conv1): Conv1d(9, 64, kernel_size=(1,), stride=(1,))\n","  (conv2): Conv1d(64, 128, kernel_size=(1,), stride=(1,))\n","  (conv3): Conv1d(128, 1024, kernel_size=(1,), stride=(1,))\n","  (conv4): Conv1d(1088, 256, kernel_size=(1,), stride=(1,))\n","  (conv5): Conv1d(256, 13, kernel_size=(1,), stride=(1,))\n","  (bn1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (bn3): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (bn4): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",")"]},"metadata":{},"execution_count":13}]},{"cell_type":"code","source":["# Compute predictions on test dataset\n","\n","# Iterate through each of the rooms\n","for i, points in enumerate(test_dataset.normalized_points):\n","    shuffle_idx = np.arange(len(points))\n","    np.random.shuffle(shuffle_idx)\n","    num_batches = int(np.ceil(1.0 * len(points) / num_resampled_points))\n","    input_points = np.zeros((1, num_resampled_points, 9), dtype=np.float32)\n","    predicted_labels = np.zeros(len(points), dtype=int)\n","\n","    print('Processing room %d with %d batches' % (i, num_batches))\n","    # Iterate through each batch of 1024 points in the room point cloud\n","    for batch_id in range(num_batches):\n","        start_idx = batch_id * num_resampled_points\n","        end_idx = (batch_id + 1) * num_resampled_points\n","        valid_idx = min(len(points), end_idx)\n","        if end_idx <= len(points):\n","            # if there are sufficient points, use all of them\n","            input_points[0, :valid_idx-start_idx] = points[shuffle_idx[start_idx:valid_idx],:]\n","        else:\n","            # if there are insufficient points to make a batch of 1024, resample from the rest of the point cloud\n","            input_points[0, :valid_idx-start_idx] = points[shuffle_idx[start_idx:valid_idx],:]\n","            input_points[0, valid_idx-end_idx:] = points[np.random.choice(range(len(points)), end_idx-valid_idx, replace=True),:]\n","\n","        with torch.no_grad():\n","            # TODO: run a forward pass through the neural network and predict the outputs\n","            pred = model(torch.from_numpy(input_points.transpose(0,2,1)).to(device))\n","\n","            # TODO: determine the output class, which should be the one predicted with maximum probability\n","            pred = pred[0].data.max(1)[1]\n","            predicted_labels[shuffle_idx[start_idx:valid_idx]] = pred[:valid_idx-start_idx].cpu().numpy()\n","\n","    # append the output class predictions to the array of predicted labels\n","    test_dataset.predicted_labels.append(predicted_labels)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eSP9DN2S6uIY","executionInfo":{"status":"ok","timestamp":1721861601375,"user_tz":300,"elapsed":1419,"user":{"displayName":"Jing Dao Chen","userId":"06340163517236512087"}},"outputId":"93dc6006-fe16-4a9f-8e9a-951e6c160542"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["Processing room 0 with 8 batches\n","Processing room 1 with 46 batches\n","Processing room 2 with 45 batches\n","Processing room 3 with 64 batches\n","Processing room 4 with 49 batches\n","Processing room 5 with 41 batches\n","Processing room 6 with 34 batches\n","Processing room 7 with 9 batches\n","Processing room 8 with 40 batches\n","Processing room 9 with 34 batches\n","Processing room 10 with 84 batches\n","Processing room 11 with 5 batches\n","Processing room 12 with 34 batches\n","Processing room 13 with 56 batches\n","Processing room 14 with 46 batches\n","Processing room 15 with 38 batches\n","Processing room 16 with 36 batches\n","Processing room 17 with 33 batches\n","Processing room 18 with 9 batches\n","Processing room 19 with 50 batches\n","Processing room 20 with 28 batches\n","Processing room 21 with 26 batches\n","Processing room 22 with 5 batches\n"]}]},{"cell_type":"code","source":["# visualize predictions for the test dataset by plotting colored point clouds\n","visualized_objects = []\n","\n","# only visualize a small number of rooms to prevent memory overflow\n","num_rooms_to_visualize = 10\n","#num_rooms_to_visualize = len(test_dataset)\n","\n","for i in range(num_rooms_to_visualize):\n","  pcd_object = o3d.geometry.PointCloud()\n","  pcd_object.points = o3d.utility.Vector3dVector(test_dataset.points[i][:, :3])\n","  # assign colors based on the predicted label for each point\n","  pcd_object.colors = o3d.utility.Vector3dVector(np.array(class_colors)[test_dataset.predicted_labels[i]])\n","  visualized_objects.append(pcd_object)\n","\n","# Visualize the point cloud using a 3D web viewer\n","draw_geometries(visualized_objects, show_axes=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":562,"output_embedded_package_id":"1W9fvyDAuglXA-c646koQh8oo-xXQYoEW"},"id":"JNSyxgHt6y3k","executionInfo":{"status":"ok","timestamp":1721861614372,"user_tz":300,"elapsed":10233,"user":{"displayName":"Jing Dao Chen","userId":"06340163517236512087"}},"outputId":"903e99e1-475b-417d-92f6-1b7e7b5a45cc"},"execution_count":15,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[],"authorship_tag":"ABX9TyO/4cvj8kDpjaMD1QavESPz"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}